{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and saving\n",
    "def save_dataframe_csv(df, path, name):\n",
    "    df.to_csv(path+name, index=False)\n",
    "\n",
    "def load_dataframe_csv(path, name, index_col=None):\n",
    "    return pd.read_csv(path+name, index_col=index_col)\n",
    "\n",
    "# Get Avearge length and success rate\n",
    "def get_average_length(df, n):\n",
    "    df_s_f = df[(df['result'] == 'successful') | (df['result'] == 'fail')]\n",
    "    iteration = df_s_f[df_s_f['target_rank']==n].groupby('user_id', as_index=False).agg({'iteration':'mean'})['iteration'].to_numpy()\n",
    "    return (np.average(iteration), 1.96*np.std(iteration)/np.sqrt(len(iteration)))\n",
    "\n",
    "def get_success_num(df, n):\n",
    "    return len(df[(df['result'] == 'successful') & (df['target_rank'] == n)])\n",
    "\n",
    "def get_fail_num(df, n):\n",
    "    return len(df[(df['result'] == 'fail') & (df['target_rank'] == n)])\n",
    "\n",
    "def get_success_rate(df, n):\n",
    "    df_s_f = df[(df['result'] == 'successful') | (df['result'] == 'fail')]\n",
    "    df_list_result = df_s_f[df_s_f['target_rank']==n].groupby('user_id')['result'].apply(list).reset_index(name='result')\n",
    "    successful_rate = df_list_result['result'].apply(lambda r: r.count(\"successful\")/len(r)).to_numpy()\n",
    "    return (np.average(successful_rate), 1.96*np.std(successful_rate)/np.sqrt(len(successful_rate)))\n",
    "\n",
    "# For creating latex table\n",
    "def get_2_metric(df, topk = 1, print_result = True):\n",
    "    if topk != 1:\n",
    "        df = change_target_rank(df,topk=topk)\n",
    "    if print_result:\n",
    "        print ('avg_length: ',get_average_length(df,topk))\n",
    "        print ('suc_rate: ',get_success_rate(df,topk))\n",
    "        return \n",
    "    else:\n",
    "        return get_average_length(df,topk), get_success_rate(df,topk)\n",
    "\n",
    "\n",
    "def latex_row(df, table_name = \"success_rate\", value_precision = 3, uncertainty_precision = 4):\n",
    "    row = {}\n",
    "    for i in columns:\n",
    "        sr, al = get_2_metric(df, topk = i,  print_result=False)\n",
    "#         print (sr,al)\n",
    "        if table_name == \"success_rate\":\n",
    "            metric = al\n",
    "        else:\n",
    "            metric = sr\n",
    "        row[i] = str(round(metric[0],value_precision)) + r'$\\pm$' + str(round(metric[1],uncertainty_precision))\n",
    "    return row\n",
    "def latex_table_row(df, table_name = \"success_rate\", value_precision = 3, uncertainty_precision = 4):\n",
    "    columns = [1,5,10,20,50] \n",
    "    table = pd.DataFrame(columns=columns)\n",
    "    row = latex_row(df, \n",
    "                     table_name = table_name, \n",
    "                     value_precision = value_precision, \n",
    "                     uncertainty_precision = uncertainty_precision)\n",
    "    table = table.append(row, ignore_index=True)\n",
    "    print (table.to_latex(escape=False))\n",
    "\n",
    "# Get tuning result \n",
    "def get_best_metric_with_single_lambda(data_path, lambs, dataset_name = \"yelp\", keyphrase_selection_method = \"random\",topk = 20, return_all = False, top_affected = None):\n",
    "    avg_lengths = []\n",
    "    suc_rates = []\n",
    "    for lamb in lambs:\n",
    "        table_name = '../tables/'  + dataset_name +   '/tune/tuning_at_lamb_'+ str(lamb)+'_with_'+ keyphrase_selection_method+'.csv'\n",
    "        if top_affected != None:\n",
    "            table_name = '../tables/'  + dataset_name +   '/tune_new_objective/topk_' + str(top_affected) + '/tuning_at_lamb_'+ str(lamb)+'_with_'+ keyphrase_selection_method+'.csv'\n",
    "        df = load_dataframe_csv(data_path, table_name)\n",
    "        avg_length, suc_rate = get_2_metric(df, topk = topk, print_result = False)\n",
    "\n",
    "        avg_lengths.append(avg_length)\n",
    "        suc_rates.append(suc_rate)\n",
    "        \n",
    "    if return_all:\n",
    "        return avg_lengths, suc_rates\n",
    "    else:\n",
    "        suc_rates_temp = [suc_rate[0] for suc_rate in suc_rates]\n",
    "        optimal_lambda_index = np.argmax(suc_rates_temp)\n",
    "#         print (optimal_lambda_index)\n",
    "        return lambs[optimal_lambda_index], avg_lengths[optimal_lambda_index], suc_rates[optimal_lambda_index]\n",
    "\n",
    "columns = [1,5,10,20,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drop_index(df, topk = 20):\n",
    "    drop_index = []\n",
    "    iter_flag = 0 \n",
    "    for i in range(len(df)):\n",
    "        if df[\"iteration\"][i] == 0:\n",
    "            iter_flag = 0\n",
    "        if df['item_rank'][i] <= topk and iter_flag == 0:\n",
    "            iter_flag = 1\n",
    "        elif iter_flag == 1:\n",
    "            drop_index.append(i)\n",
    "    return drop_index \n",
    "\n",
    "def change_target_rank(df,topk = 20):\n",
    "    modified_df = df.drop(get_drop_index(df,topk = topk))\n",
    "    modified_df = modified_df.reset_index(drop=True)\n",
    "    modified_df['target_rank'] = topk\n",
    "    for i in range(len(modified_df)):\n",
    "        if modified_df['item_rank'][i] <= modified_df['target_rank'][i]:\n",
    "            modified_df.at[i,\"result\"] = \"successful\"\n",
    "    return modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_freq(df, precision = 1, theta_col = \"theta\"):\n",
    "    \"\"\"\n",
    "    get theta freq for entire dataframe\n",
    "    store in dictionary\n",
    "    \"\"\"\n",
    "    theta_freq = defaultdict(int)\n",
    "    for i in range(len(df)):\n",
    "        # Theta line\n",
    "#         try:\n",
    "        theta_line = literal_eval(df[theta_col][i])\n",
    "#             theta_freq = get_list_freqs(theta_freq, theta_line, precision=precision)\n",
    "        for i in range(len(theta_line)):\n",
    "            if precision == None:\n",
    "                theta_freq[theta_line[i]] += 1\n",
    "            else:\n",
    "                val = round(theta_line[i], precision)\n",
    "                theta_freq[val] += 1\n",
    "#         except:\n",
    "            continue\n",
    "    return theta_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &                1  &                5  &                10 &               20 &                50 \\\\\n",
      "\\midrule\n",
      "0 &  0.0171$\\pm$0.023 &  0.0274$\\pm$0.025 &  0.0686$\\pm$0.037 &  0.106$\\pm$0.041 &  0.2074$\\pm$0.054 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &              1  &               5  &               10 &               20 &               50 \\\\\n",
      "\\midrule\n",
      "0 &  6.44$\\pm$0.492 &  6.396$\\pm$0.495 &  6.301$\\pm$0.502 &  6.208$\\pm$0.511 &  5.879$\\pm$0.521 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uac random\n",
    "df = load_dataframe_csv(\"../tables/reproduce/beer/uac_random.csv\",\"\")\n",
    "latex_table_row(df, table_name = \"success_rate\", value_precision = 4, uncertainty_precision = 3)\n",
    "latex_table_row(df, table_name = \"avg_length\", value_precision = 3, uncertainty_precision = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &                1  &                5  &                10 &                20 &                50 \\\\\n",
      "\\midrule\n",
      "0 &  0.0286$\\pm$0.032 &  0.0528$\\pm$0.035 &  0.0792$\\pm$0.039 &  0.1093$\\pm$0.042 &  0.2142$\\pm$0.054 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &               1  &               5  &               10 &               20 &               50 \\\\\n",
      "\\midrule\n",
      "0 &  9.806$\\pm$0.216 &  9.622$\\pm$0.263 &  9.349$\\pm$0.331 &  9.075$\\pm$0.359 &  8.082$\\pm$0.484 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uac diff\n",
    "df = load_dataframe_csv(\"../tables/reproduce/beer/uac_diff.csv\",\"\")\n",
    "latex_table_row(df, table_name = \"success_rate\", value_precision = 4, uncertainty_precision = 3)\n",
    "latex_table_row(df, table_name = \"avg_length\", value_precision = 3, uncertainty_precision = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
